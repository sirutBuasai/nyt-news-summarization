{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvoGHJJvOyAe"
      },
      "source": [
        "# New York Times News Summarization\n",
        "Sirut Buasai, sbausai2@wpi.edu <br>\n",
        "Jason Dykstra, jpdykstra@wpi.edu <br>\n",
        "Adam Yang ayang@wpi.edu\n",
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "emBF0izoOyAo",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/sirutbuasai/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/sirutbuasai/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# Data Processing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Text Processing\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag_sents\n",
        "\n",
        "# Model Building\n",
        "import tensorflow as tf\n",
        "from keras.utils import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Metrics\n",
        "from sacrebleu.metrics import BLEU\n",
        "from rouge import Rouge\n",
        "\n",
        "# Google Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# Downloads\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "NER = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B73993JWevBU"
      },
      "source": [
        "## Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "ntkhyPUaevBU"
      },
      "outputs": [],
      "source": [
        "MAX_ABSTRACT_LEN = 30\n",
        "MAX_TITLE_LEN = 12\n",
        "LATENT_DIMENSION = 300 \n",
        "EMBEDDING_DIMENSION = 100 \n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 128\n",
        "DATA_SET_RATIO = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEs_PaTROyAs"
      },
      "source": [
        "## Data Pre-processing\n",
        "### Initial Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "id": "zEDTd5yNOyAu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataframe shape: (106, 7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>abstract</th>\n",
              "      <th>Date</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>nyt://article/178801fe-4679-5f12-985f-8344a86e...</td>\n",
              "      <td>In Reversal, Pakistan Welcomes Outside Help Wi...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Pakistan’s ambassador to the U.S. said his gov...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['Assassinations and Attempted Assassinations'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>nyt://article/21acedcb-a7f6-5131-99cf-d3a47e33...</td>\n",
              "      <td>Fighting Intensifies After Election in Kenya</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Kenya sank deeper into trouble, with a curfew ...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['Kenya', 'Demonstrations and Riots', 'Odinga,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nyt://article/357b5429-a9f8-5d33-a5eb-c013a201...</td>\n",
              "      <td>Israel: Olmert Curbs Settlements</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Prime Minister Ehud Olmert has sent a letter t...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['West Bank']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>nyt://article/619ca4ea-50e4-59e4-97bb-f206502c...</td>\n",
              "      <td>Gay Muslims Pack a Dance Floor of Their Own</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>The monthly club night known as Gayhane is an ...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['Homosexuality', 'Islam', 'IMMIGRATION AND RE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>nyt://article/73c49a5a-bcf1-5b8f-a15a-98d29003...</td>\n",
              "      <td>Iraqi Revelers Embrace the New Year</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>But even as partygoers embraced the New Year, ...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['ARMAMENT, DEFENSE AND MILITARY FORCES', 'Iraq']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>101</td>\n",
              "      <td>nyt://slideshow/dbf99825-09fb-5f03-bb04-da2d02...</td>\n",
              "      <td>Mortgages and Women</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>The focus of conversation at hair salons in Ba...</td>\n",
              "      <td>2008-01-08 08:39:00+00:00</td>\n",
              "      <td>['Mortgages', 'Baltimore (Md)']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>nyt://slideshow/4b7032f0-8c1a-5895-9654-c2ff26...</td>\n",
              "      <td>Voting in New Hampshire</td>\n",
              "      <td>U.S.</td>\n",
              "      <td>Primary voters streamed to the polls in New Ha...</td>\n",
              "      <td>2008-01-08 17:45:01+00:00</td>\n",
              "      <td>['Presidential Election of 2008', 'PRIMARIES',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>103</td>\n",
              "      <td>nyt://article/077f5a51-d939-58e0-8074-ea9974d1...</td>\n",
              "      <td>At Gaza’s Edge, Israelis Fear Rockets’ Whine</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Sderot, Israel, a working-class town less than...</td>\n",
              "      <td>2008-01-09 05:00:00+00:00</td>\n",
              "      <td>['Palestinians', 'Israel', 'Gaza Strip', 'Bomb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>104</td>\n",
              "      <td>nyt://article/09196e5e-98d3-5070-a235-c005b505...</td>\n",
              "      <td>Jean-Claude Vrinat, Owner of Famed Paris Resta...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>For more than three decades, Mr. Vrinat was th...</td>\n",
              "      <td>2008-01-09 05:00:00+00:00</td>\n",
              "      <td>['Restaurants', 'France', 'Taillevent', 'Death...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>105</td>\n",
              "      <td>nyt://article/0a88b90c-3fc1-5379-a206-918172a4...</td>\n",
              "      <td>Mideast Leaders Agree to Core Talks</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>The Israeli and Palestinian leaders authorized...</td>\n",
              "      <td>2008-01-09 05:00:00+00:00</td>\n",
              "      <td>['Lebanon', 'Palestinians', 'Israel', 'Bush, G...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0                                                 ID  \\\n",
              "0             0  nyt://article/178801fe-4679-5f12-985f-8344a86e...   \n",
              "1             1  nyt://article/21acedcb-a7f6-5131-99cf-d3a47e33...   \n",
              "2             2  nyt://article/357b5429-a9f8-5d33-a5eb-c013a201...   \n",
              "3             3  nyt://article/619ca4ea-50e4-59e4-97bb-f206502c...   \n",
              "4             4  nyt://article/73c49a5a-bcf1-5b8f-a15a-98d29003...   \n",
              "..          ...                                                ...   \n",
              "101         101  nyt://slideshow/dbf99825-09fb-5f03-bb04-da2d02...   \n",
              "102         102  nyt://slideshow/4b7032f0-8c1a-5895-9654-c2ff26...   \n",
              "103         103  nyt://article/077f5a51-d939-58e0-8074-ea9974d1...   \n",
              "104         104  nyt://article/09196e5e-98d3-5070-a235-c005b505...   \n",
              "105         105  nyt://article/0a88b90c-3fc1-5379-a206-918172a4...   \n",
              "\n",
              "                                                 title    topic  \\\n",
              "0    In Reversal, Pakistan Welcomes Outside Help Wi...  Foreign   \n",
              "1         Fighting Intensifies After Election in Kenya  Foreign   \n",
              "2                     Israel: Olmert Curbs Settlements  Foreign   \n",
              "3          Gay Muslims Pack a Dance Floor of Their Own  Foreign   \n",
              "4                  Iraqi Revelers Embrace the New Year  Foreign   \n",
              "..                                                 ...      ...   \n",
              "101                                Mortgages and Women     U.S.   \n",
              "102                            Voting in New Hampshire     U.S.   \n",
              "103       At Gaza’s Edge, Israelis Fear Rockets’ Whine  Foreign   \n",
              "104  Jean-Claude Vrinat, Owner of Famed Paris Resta...  Foreign   \n",
              "105                Mideast Leaders Agree to Core Talks  Foreign   \n",
              "\n",
              "                                              abstract  \\\n",
              "0    Pakistan’s ambassador to the U.S. said his gov...   \n",
              "1    Kenya sank deeper into trouble, with a curfew ...   \n",
              "2    Prime Minister Ehud Olmert has sent a letter t...   \n",
              "3    The monthly club night known as Gayhane is an ...   \n",
              "4    But even as partygoers embraced the New Year, ...   \n",
              "..                                                 ...   \n",
              "101  The focus of conversation at hair salons in Ba...   \n",
              "102  Primary voters streamed to the polls in New Ha...   \n",
              "103  Sderot, Israel, a working-class town less than...   \n",
              "104  For more than three decades, Mr. Vrinat was th...   \n",
              "105  The Israeli and Palestinian leaders authorized...   \n",
              "\n",
              "                          Date  \\\n",
              "0    2008-01-01 05:00:00+00:00   \n",
              "1    2008-01-01 05:00:00+00:00   \n",
              "2    2008-01-01 05:00:00+00:00   \n",
              "3    2008-01-01 05:00:00+00:00   \n",
              "4    2008-01-01 05:00:00+00:00   \n",
              "..                         ...   \n",
              "101  2008-01-08 08:39:00+00:00   \n",
              "102  2008-01-08 17:45:01+00:00   \n",
              "103  2008-01-09 05:00:00+00:00   \n",
              "104  2008-01-09 05:00:00+00:00   \n",
              "105  2008-01-09 05:00:00+00:00   \n",
              "\n",
              "                                              keywords  \n",
              "0    ['Assassinations and Attempted Assassinations'...  \n",
              "1    ['Kenya', 'Demonstrations and Riots', 'Odinga,...  \n",
              "2                                        ['West Bank']  \n",
              "3    ['Homosexuality', 'Islam', 'IMMIGRATION AND RE...  \n",
              "4    ['ARMAMENT, DEFENSE AND MILITARY FORCES', 'Iraq']  \n",
              "..                                                 ...  \n",
              "101                    ['Mortgages', 'Baltimore (Md)']  \n",
              "102  ['Presidential Election of 2008', 'PRIMARIES',...  \n",
              "103  ['Palestinians', 'Israel', 'Gaza Strip', 'Bomb...  \n",
              "104  ['Restaurants', 'France', 'Taillevent', 'Death...  \n",
              "105  ['Lebanon', 'Palestinians', 'Israel', 'Bush, G...  \n",
              "\n",
              "[106 rows x 7 columns]"
            ]
          },
          "execution_count": 343,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data_path = 'NYT_Dataset.csv'\n",
        "raw_data = pd.read_csv(raw_data_path)\n",
        "raw_data = raw_data[:int(DATA_SET_RATIO*len(raw_data))]\n",
        "print(f'dataframe shape: {raw_data.shape}')\n",
        "raw_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP0xgBIqOyAv"
      },
      "source": [
        "### Clean Data\n",
        "#### Part of Speech Processing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "id": "lt2rCg-K7bn-"
      },
      "outputs": [],
      "source": [
        "def pos_processing(abstract_sentences):\n",
        "  abstract_tokens = pd.Series(abstract_sentences.apply(lambda sentence: sentence.split()))\n",
        "\n",
        "  # identify parts-of-speech; pos_tag requires list of tokens\n",
        "  abstract_pos = pd.Series(pos_tag_sents(abstract_tokens))\n",
        "\n",
        "  # filter non-desirable parts-of-speech\n",
        "  nounsList = ['NN', 'NNS', 'NNP', 'NNPS'] # Nouns\n",
        "  verbsList = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VPZ'] # Verbs\n",
        "  adjList = ['JJ', 'JJR', 'JJS'] # Adjectives\n",
        "  pos_list = nounsList + verbsList + adjList\n",
        "  abstract_pos_filtered = abstract_pos.apply(lambda words: ' '.join([pair[0] for pair in words if pair[1] in pos_list]))\n",
        "\n",
        "  return abstract_pos_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRQSO8eevBY"
      },
      "source": [
        "#### NER Processing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "8eN1mcbw8rbj"
      },
      "outputs": [],
      "source": [
        "def ner_processing(abstract_sentences):\n",
        "  # identify entities for each abstract\n",
        "  abs_entities = pd.Series(abstract_sentences.apply(lambda sentence: NER(sentence)))\n",
        "\n",
        "  # extract the original sentences, but now with split contractions and the entity type from NER\n",
        "  original_sentence = pd.Series(abs_entities.apply(lambda entities: ' '.join([f\"{token.orth_}<{token.ent_type_}>\" if token.ent_type_ else f\"{token.orth_}\" for token in entities])))\n",
        "\n",
        "  return original_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPpI_mowevBZ"
      },
      "source": [
        "#### Clean Text Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "dvJXzEeFOyAw",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataframe shape: (106, 8)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>cleaned_title</th>\n",
              "      <th>cleaned_abstract</th>\n",
              "      <th>cleaned_abstract_pos</th>\n",
              "      <th>cleaned_abstract_pos_keywords</th>\n",
              "      <th>cleaned_abstract_pos_ner</th>\n",
              "      <th>cleaned_abstract_pos_keywords_ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in reversal, pakistan welcomes outside help wi...</td>\n",
              "      <td>pakistan’s ambassador to the u.s. said his gov...</td>\n",
              "      <td>sostok reversal pakistan welcomes outside help...</td>\n",
              "      <td>pakistans ambassador us said government would ...</td>\n",
              "      <td>pakistans ambassador said government endorse s...</td>\n",
              "      <td>pakistans ambassador said government endorse s...</td>\n",
              "      <td>pakistans&lt;NORP&gt; ambassador said government end...</td>\n",
              "      <td>pakistans&lt;NORP&gt; ambassador said government end...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fighting intensifies after election in kenya</td>\n",
              "      <td>kenya sank deeper into trouble, with a curfew ...</td>\n",
              "      <td>sostok fighting intensifies election kenya eostok</td>\n",
              "      <td>kenya sank deeper trouble curfew imposed kisum...</td>\n",
              "      <td>kenya sank trouble curfew imposed kisumu count...</td>\n",
              "      <td>kenya sank trouble curfew imposed kisumu count...</td>\n",
              "      <td>kenya&lt;PERSON&gt; sank trouble curfew imposed kisu...</td>\n",
              "      <td>kenya&lt;PERSON&gt; sank trouble curfew imposed kisu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>israel: olmert curbs settlements</td>\n",
              "      <td>prime minister ehud olmert has sent a letter t...</td>\n",
              "      <td>sostok israel olmert curbs settlements eostok</td>\n",
              "      <td>prime minister ehud olmert sent letter defense...</td>\n",
              "      <td>prime minister ehud olmert sent letter defense...</td>\n",
              "      <td>prime minister ehud olmert sent letter defense...</td>\n",
              "      <td>prime minister ehud&lt;PERSON&gt; olmert&lt;PERSON&gt; sen...</td>\n",
              "      <td>prime minister ehud&lt;PERSON&gt; olmert&lt;PERSON&gt; sen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gay muslims pack a dance floor of their own</td>\n",
              "      <td>the monthly club night known as gayhane is an ...</td>\n",
              "      <td>sostok gay muslims pack dance floor eostok</td>\n",
              "      <td>monthly club night known gayhane alltoorare op...</td>\n",
              "      <td>club night known gayhane alltoorare opportunit...</td>\n",
              "      <td>club night known gayhane alltoorare opportunit...</td>\n",
              "      <td>club night known gayhane alltoorare opportunit...</td>\n",
              "      <td>club night known gayhane alltoorare opportunit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>iraqi revelers embrace the new year</td>\n",
              "      <td>but even as partygoers embraced the new year, ...</td>\n",
              "      <td>sostok iraqi revelers embrace new year eostok</td>\n",
              "      <td>even partygoers embraced new year surge attack...</td>\n",
              "      <td>partygoers embraced new year surge attacks mon...</td>\n",
              "      <td>partygoers embraced new year surge attacks mon...</td>\n",
              "      <td>partygoers embraced new year&lt;DATE&gt; surge attac...</td>\n",
              "      <td>partygoers embraced new year&lt;DATE&gt; surge attac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>mortgages and women</td>\n",
              "      <td>the focus of conversation at hair salons in ba...</td>\n",
              "      <td>sostok mortgages women eostok</td>\n",
              "      <td>focus conversation hair salons baltimore turne...</td>\n",
              "      <td>focus conversation hair salons baltimore turne...</td>\n",
              "      <td>focus conversation hair salons baltimore turne...</td>\n",
              "      <td>focus conversation hair salons baltimore turne...</td>\n",
              "      <td>focus conversation hair salons baltimore turne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>voting in new hampshire</td>\n",
              "      <td>primary voters streamed to the polls in new ha...</td>\n",
              "      <td>sostok voting new hampshire eostok</td>\n",
              "      <td>primary voters streamed polls new hampshire el...</td>\n",
              "      <td>primary voters streamed polls new hampshire el...</td>\n",
              "      <td>primary voters streamed polls new hampshire el...</td>\n",
              "      <td>primary voters streamed polls new hampshire el...</td>\n",
              "      <td>primary voters streamed polls new hampshire el...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>at gaza’s edge, israelis fear rockets’ whine</td>\n",
              "      <td>sderot, israel, a working-class town less than...</td>\n",
              "      <td>sostok gazas edge israelis fear rockets whine ...</td>\n",
              "      <td>sderot israel workingclass town less two miles...</td>\n",
              "      <td>sderot israel workingclass town miles hit rockets</td>\n",
              "      <td>sderot israel workingclass town miles hit rock...</td>\n",
              "      <td>sderot israel&lt;GPE&gt; workingclass town miles hit...</td>\n",
              "      <td>sderot israel&lt;GPE&gt; workingclass town miles hit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>jean-claude vrinat, owner of famed paris resta...</td>\n",
              "      <td>for more than three decades, mr. vrinat was th...</td>\n",
              "      <td>sostok jeanclaude vrinat owner famed paris res...</td>\n",
              "      <td>three decades mr vrinat owner taillevent resta...</td>\n",
              "      <td>decades mr vrinat owner taillevent restaurant ...</td>\n",
              "      <td>decades mr vrinat owner taillevent restaurant ...</td>\n",
              "      <td>decades&lt;DATE&gt; mr vrinat owner taillevent resta...</td>\n",
              "      <td>decades&lt;DATE&gt; mr vrinat owner taillevent resta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>mideast leaders agree to core talks</td>\n",
              "      <td>the israeli and palestinian leaders authorized...</td>\n",
              "      <td>sostok mideast leaders agree core talks eostok</td>\n",
              "      <td>israeli palestinian leaders authorized start n...</td>\n",
              "      <td>israeli palestinian leaders authorized start n...</td>\n",
              "      <td>israeli palestinian leaders authorized start n...</td>\n",
              "      <td>israeli&lt;NORP&gt; palestinian&lt;NORP&gt; leaders author...</td>\n",
              "      <td>israeli&lt;NORP&gt; palestinian&lt;NORP&gt; leaders author...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>106 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 title  \\\n",
              "0    in reversal, pakistan welcomes outside help wi...   \n",
              "1         fighting intensifies after election in kenya   \n",
              "2                     israel: olmert curbs settlements   \n",
              "3          gay muslims pack a dance floor of their own   \n",
              "4                  iraqi revelers embrace the new year   \n",
              "..                                                 ...   \n",
              "101                                mortgages and women   \n",
              "102                            voting in new hampshire   \n",
              "103       at gaza’s edge, israelis fear rockets’ whine   \n",
              "104  jean-claude vrinat, owner of famed paris resta...   \n",
              "105                mideast leaders agree to core talks   \n",
              "\n",
              "                                              abstract  \\\n",
              "0    pakistan’s ambassador to the u.s. said his gov...   \n",
              "1    kenya sank deeper into trouble, with a curfew ...   \n",
              "2    prime minister ehud olmert has sent a letter t...   \n",
              "3    the monthly club night known as gayhane is an ...   \n",
              "4    but even as partygoers embraced the new year, ...   \n",
              "..                                                 ...   \n",
              "101  the focus of conversation at hair salons in ba...   \n",
              "102  primary voters streamed to the polls in new ha...   \n",
              "103  sderot, israel, a working-class town less than...   \n",
              "104  for more than three decades, mr. vrinat was th...   \n",
              "105  the israeli and palestinian leaders authorized...   \n",
              "\n",
              "                                         cleaned_title  \\\n",
              "0    sostok reversal pakistan welcomes outside help...   \n",
              "1    sostok fighting intensifies election kenya eostok   \n",
              "2        sostok israel olmert curbs settlements eostok   \n",
              "3           sostok gay muslims pack dance floor eostok   \n",
              "4        sostok iraqi revelers embrace new year eostok   \n",
              "..                                                 ...   \n",
              "101                      sostok mortgages women eostok   \n",
              "102                 sostok voting new hampshire eostok   \n",
              "103  sostok gazas edge israelis fear rockets whine ...   \n",
              "104  sostok jeanclaude vrinat owner famed paris res...   \n",
              "105     sostok mideast leaders agree core talks eostok   \n",
              "\n",
              "                                      cleaned_abstract  \\\n",
              "0    pakistans ambassador us said government would ...   \n",
              "1    kenya sank deeper trouble curfew imposed kisum...   \n",
              "2    prime minister ehud olmert sent letter defense...   \n",
              "3    monthly club night known gayhane alltoorare op...   \n",
              "4    even partygoers embraced new year surge attack...   \n",
              "..                                                 ...   \n",
              "101  focus conversation hair salons baltimore turne...   \n",
              "102  primary voters streamed polls new hampshire el...   \n",
              "103  sderot israel workingclass town less two miles...   \n",
              "104  three decades mr vrinat owner taillevent resta...   \n",
              "105  israeli palestinian leaders authorized start n...   \n",
              "\n",
              "                                  cleaned_abstract_pos  \\\n",
              "0    pakistans ambassador said government endorse s...   \n",
              "1    kenya sank trouble curfew imposed kisumu count...   \n",
              "2    prime minister ehud olmert sent letter defense...   \n",
              "3    club night known gayhane alltoorare opportunit...   \n",
              "4    partygoers embraced new year surge attacks mon...   \n",
              "..                                                 ...   \n",
              "101  focus conversation hair salons baltimore turne...   \n",
              "102  primary voters streamed polls new hampshire el...   \n",
              "103  sderot israel workingclass town miles hit rockets   \n",
              "104  decades mr vrinat owner taillevent restaurant ...   \n",
              "105  israeli palestinian leaders authorized start n...   \n",
              "\n",
              "                         cleaned_abstract_pos_keywords  \\\n",
              "0    pakistans ambassador said government endorse s...   \n",
              "1    kenya sank trouble curfew imposed kisumu count...   \n",
              "2    prime minister ehud olmert sent letter defense...   \n",
              "3    club night known gayhane alltoorare opportunit...   \n",
              "4    partygoers embraced new year surge attacks mon...   \n",
              "..                                                 ...   \n",
              "101  focus conversation hair salons baltimore turne...   \n",
              "102  primary voters streamed polls new hampshire el...   \n",
              "103  sderot israel workingclass town miles hit rock...   \n",
              "104  decades mr vrinat owner taillevent restaurant ...   \n",
              "105  israeli palestinian leaders authorized start n...   \n",
              "\n",
              "                              cleaned_abstract_pos_ner  \\\n",
              "0    pakistans<NORP> ambassador said government end...   \n",
              "1    kenya<PERSON> sank trouble curfew imposed kisu...   \n",
              "2    prime minister ehud<PERSON> olmert<PERSON> sen...   \n",
              "3    club night known gayhane alltoorare opportunit...   \n",
              "4    partygoers embraced new year<DATE> surge attac...   \n",
              "..                                                 ...   \n",
              "101  focus conversation hair salons baltimore turne...   \n",
              "102  primary voters streamed polls new hampshire el...   \n",
              "103  sderot israel<GPE> workingclass town miles hit...   \n",
              "104  decades<DATE> mr vrinat owner taillevent resta...   \n",
              "105  israeli<NORP> palestinian<NORP> leaders author...   \n",
              "\n",
              "                     cleaned_abstract_pos_keywords_ner  \n",
              "0    pakistans<NORP> ambassador said government end...  \n",
              "1    kenya<PERSON> sank trouble curfew imposed kisu...  \n",
              "2    prime minister ehud<PERSON> olmert<PERSON> sen...  \n",
              "3    club night known gayhane alltoorare opportunit...  \n",
              "4    partygoers embraced new year<DATE> surge attac...  \n",
              "..                                                 ...  \n",
              "101  focus conversation hair salons baltimore turne...  \n",
              "102  primary voters streamed polls new hampshire el...  \n",
              "103  sderot israel<GPE> workingclass town miles hit...  \n",
              "104  decades<DATE> mr vrinat owner taillevent resta...  \n",
              "105  israeli<NORP> palestinian<NORP> leaders author...  \n",
              "\n",
              "[106 rows x 8 columns]"
            ]
          },
          "execution_count": 346,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess_data(df):\n",
        "  # drop unnecessary columns\n",
        "  unused_columns = ['Unnamed: 0', 'Date', 'ID']\n",
        "  df.drop(unused_columns, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "  # drop dupliates and nan rows\n",
        "  df.drop_duplicates(subset=['abstract'], inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  df.dropna(axis=0, inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  # convert texts to lowercase\n",
        "  df['abstract'] = df['abstract'].str.lower()\n",
        "  df['title'] = df['title'].str.lower()\n",
        "  df['keywords'] = df['keywords'].str.lower()\n",
        "  df['topic'] = df['topic'].str.lower()\n",
        "\n",
        "  # strip special characters\n",
        "  df['cleaned_title'] = df['title'].apply(lambda text: re.sub(\"[^a-zA-Z0-9 ]+\", '', text))\n",
        "  df['cleaned_abstract'] = df['abstract'].apply(lambda text: re.sub(\"[^a-zA-Z0-9 ]+\", '', text))\n",
        "  df['cleaned_keywords'] = df['keywords'].apply(lambda text: re.sub(\"[^a-zA-Z0-9 ]+\", '', text))\n",
        "  df['cleaned_topic'] = df['topic'].apply(lambda text: re.sub(\"[^a-zA-Z0-9 ]+\", '', text))\n",
        "\n",
        "  # add keywords and topics\n",
        "  df['cleaned_keywords'] = df['cleaned_keywords'].apply(lambda sentence: \"\".join(word for word in sentence))\n",
        "  df['cleaned_abstract_keywords'] = df['cleaned_abstract'] + df['cleaned_keywords'] + ' ' + df['topic']\n",
        "\n",
        "  # convert string to list\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda text: text.split())\n",
        "  df['cleaned_abstract'] = df['cleaned_abstract'].apply(lambda text: text.split())\n",
        "  df['cleaned_abstract_keywords'] = df['cleaned_abstract_keywords'].apply(lambda text: text.split())\n",
        "\n",
        "  # remove stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda sentence: [word for word in sentence if word not in (stop_words)])\n",
        "  df['cleaned_abstract'] = df['cleaned_abstract'].apply(lambda sentence: [word for word in sentence if word not in (stop_words)])\n",
        "  df['cleaned_abstract_keywords'] = df['cleaned_abstract_keywords'].apply(lambda sentence: [word for word in sentence if word not in (stop_words)])\n",
        "\n",
        "  # convert list back to string\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda sentence: \" \".join(word for word in sentence))\n",
        "  df['cleaned_abstract'] = df['cleaned_abstract'].apply(lambda sentence: \" \".join(word for word in sentence))\n",
        "  df['cleaned_abstract_keywords'] = df['cleaned_abstract_keywords'].apply(lambda sentence: \" \".join(word for word in sentence))\n",
        "\n",
        "    # filter and keep noun, verbs, and adj words; requires string sentences\n",
        "  df['cleaned_abstract_pos'] = pos_processing(df['cleaned_abstract'])\n",
        "  df['cleaned_abstract_pos_keywords'] = pos_processing(df['cleaned_abstract_keywords'])\n",
        "\n",
        "  # identify named-entities; NER requires string sentences\n",
        "  df['cleaned_abstract_pos_ner'] = ner_processing(df['cleaned_abstract_pos'])\n",
        "  df['cleaned_abstract_pos_keywords_ner'] = ner_processing(df['cleaned_abstract_pos_keywords'])\n",
        "    \n",
        "  # add start and end tokens for title\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda text: 'sostok ' + text + ' eostok')\n",
        "\n",
        "  # drop unnecessary columns\n",
        "  unnecessary_columns = ['topic', 'keywords', 'cleaned_keywords', 'cleaned_topic', 'cleaned_abstract_keywords']\n",
        "  df.drop(unnecessary_columns, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "  return df\n",
        "\n",
        "cleaned_data = preprocess_data(raw_data)\n",
        "print(f'dataframe shape: {cleaned_data.shape}')\n",
        "cleaned_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Abstract:\n",
            "\t pakistan’s ambassador to the u.s. said his government would not endorse a separate inquiry modeled after one carried out by the u.n. after the assassination of rafik hariri of lebanon in 2005.\n",
            "Title:\n",
            "\t in reversal, pakistan welcomes outside help with  inquiry on bhutto\n",
            "\n",
            "\n",
            "Cleaned Abstract:\n",
            "\t pakistans ambassador us said government would endorse separate inquiry modeled one carried un assassination rafik hariri lebanon 2005\n",
            "Cleaned Abstract with POS:\n",
            "\t pakistans ambassador said government endorse separate inquiry modeled carried un assassination rafik hariri lebanon\n",
            "Cleaned Abstract with POS and Keywords:\n",
            "\t pakistans ambassador said government endorse separate inquiry modeled carried un assassination rafik hariri lebanon attempted assassinations pakistan bhutto benazir federal bureau investigation united nations foreign\n",
            "Cleaned Abstract with POS and NER:\n",
            "\t pakistans<NORP> ambassador said government endorse separate inquiry modeled carried un<ORG> assassination rafik hariri lebanon<GPE>\n",
            "Cleaned Abstract with POS and Keywords and NER:\n",
            "\t pakistans<NORP> ambassador said government endorse separate inquiry modeled carried un<ORG> assassination rafik hariri lebanon<GPE> attempted assassinations pakistan<GPE> bhutto benazir federal<ORG> bureau<ORG> investigation united nations foreign\n",
            "Cleaned Title:\n",
            "\t sostok reversal pakistan welcomes outside help inquiry bhutto eostok\n",
            "\n",
            "\n",
            "Abstract:\n",
            "\t kenya sank deeper into trouble, with a curfew imposed in kisumu, the country’s third-largest city, ethnic fighting intensifying and more than 100 people killed in election-related violence.\n",
            "Title:\n",
            "\t fighting intensifies after election in kenya\n",
            "\n",
            "\n",
            "Cleaned Abstract:\n",
            "\t kenya sank deeper trouble curfew imposed kisumu countrys thirdlargest city ethnic fighting intensifying 100 people killed electionrelated violence\n",
            "Cleaned Abstract with POS:\n",
            "\t kenya sank trouble curfew imposed kisumu countrys thirdlargest city ethnic fighting intensifying people killed electionrelated violence\n",
            "Cleaned Abstract with POS and Keywords:\n",
            "\t kenya sank trouble curfew imposed kisumu countrys thirdlargest city ethnic fighting intensifying people killed electionrelated violencekenya demonstrations riots odinga raila kibaki mwai elections foreign\n",
            "Cleaned Abstract with POS and NER:\n",
            "\t kenya<PERSON> sank trouble curfew imposed kisumu countrys thirdlargest city ethnic fighting intensifying people killed electionrelated violence\n",
            "Cleaned Abstract with POS and Keywords and NER:\n",
            "\t kenya<PERSON> sank trouble curfew imposed kisumu countrys thirdlargest city ethnic fighting intensifying people killed electionrelated violencekenya<PERSON> demonstrations riots odinga raila<PERSON> kibaki<PERSON> mwai<PERSON> elections foreign\n",
            "Cleaned Title:\n",
            "\t sostok fighting intensifies election kenya eostok\n",
            "\n",
            "\n",
            "Abstract:\n",
            "\t prime minister ehud olmert has sent a letter to defense, housing and agriculture ministers, saying that his and the defense minister’s authorization would be required for any new building, planning or land expropriation for jewish settlements in the west bank.\n",
            "Title:\n",
            "\t israel: olmert curbs settlements\n",
            "\n",
            "\n",
            "Cleaned Abstract:\n",
            "\t prime minister ehud olmert sent letter defense housing agriculture ministers saying defense ministers authorization would required new building planning land expropriation jewish settlements west bank\n",
            "Cleaned Abstract with POS:\n",
            "\t prime minister ehud olmert sent letter defense housing agriculture ministers saying defense ministers authorization required new building planning land expropriation jewish settlements west bank\n",
            "Cleaned Abstract with POS and Keywords:\n",
            "\t prime minister ehud olmert sent letter defense housing agriculture ministers saying defense ministers authorization required new building planning land expropriation jewish settlements west bankwest bank foreign\n",
            "Cleaned Abstract with POS and NER:\n",
            "\t prime minister ehud<PERSON> olmert<PERSON> sent letter defense housing agriculture ministers saying defense ministers authorization required new building planning land expropriation jewish<NORP> settlements west<GPE> bank<GPE>\n",
            "Cleaned Abstract with POS and Keywords and NER:\n",
            "\t prime minister ehud<PERSON> olmert<PERSON> sent letter defense housing agriculture ministers saying defense ministers authorization required new building planning land expropriation jewish<NORP> settlements west<GPE> bankwest<GPE> bank<GPE> foreign\n",
            "Cleaned Title:\n",
            "\t sostok israel olmert curbs settlements eostok\n",
            "\n",
            "\n",
            "Abstract:\n",
            "\t the monthly club night known as gayhane is an all-too-rare opportunity for gay muslims to merge their immigrant cultures and their sexual identities.\n",
            "Title:\n",
            "\t gay muslims pack a dance floor of their own\n",
            "\n",
            "\n",
            "Cleaned Abstract:\n",
            "\t monthly club night known gayhane alltoorare opportunity gay muslims merge immigrant cultures sexual identities\n",
            "Cleaned Abstract with POS:\n",
            "\t club night known gayhane alltoorare opportunity gay muslims merge immigrant cultures sexual identities\n",
            "Cleaned Abstract with POS and Keywords:\n",
            "\t club night known gayhane alltoorare opportunity gay muslims merge immigrant cultures sexual identitieshomosexuality islam immigration berlin germany foreign\n",
            "Cleaned Abstract with POS and NER:\n",
            "\t club night known gayhane alltoorare opportunity gay muslims<NORP> merge immigrant cultures sexual identities\n",
            "Cleaned Abstract with POS and Keywords and NER:\n",
            "\t club night known gayhane alltoorare opportunity gay muslims<NORP> merge immigrant cultures sexual identitieshomosexuality islam<GPE> immigration berlin<GPE> germany<GPE> foreign\n",
            "Cleaned Title:\n",
            "\t sostok gay muslims pack dance floor eostok\n",
            "\n",
            "\n",
            "Abstract:\n",
            "\t but even as partygoers embraced the new year, a surge of attacks on monday served as a potent reminder that 2007 was the bloodiest on record.\n",
            "Title:\n",
            "\t iraqi revelers embrace the new year\n",
            "\n",
            "\n",
            "Cleaned Abstract:\n",
            "\t even partygoers embraced new year surge attacks monday served potent reminder 2007 bloodiest record\n",
            "Cleaned Abstract with POS:\n",
            "\t partygoers embraced new year surge attacks monday served potent reminder bloodiest record\n",
            "Cleaned Abstract with POS and Keywords:\n",
            "\t partygoers embraced new year surge attacks monday served potent reminder bloodiest recordarmament defense military forces iraq foreign\n",
            "Cleaned Abstract with POS and NER:\n",
            "\t partygoers embraced new year<DATE> surge attacks monday<DATE> served potent reminder bloodiest record\n",
            "Cleaned Abstract with POS and Keywords and NER:\n",
            "\t partygoers embraced new year<DATE> surge attacks monday<DATE> served potent reminder bloodiest recordarmament defense military forces iraq<GPE> foreign\n",
            "Cleaned Title:\n",
            "\t sostok iraqi revelers embrace new year eostok\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  print(\"Abstract:\\n\\t\", cleaned_data['abstract'][i])\n",
        "  print(\"Title:\\n\\t\", cleaned_data['title'][i])\n",
        "  print(\"\\n\")\n",
        "  print(\"Cleaned Abstract:\\n\\t\", cleaned_data['cleaned_abstract'][i])\n",
        "  print(\"Cleaned Abstract with POS:\\n\\t\", cleaned_data['cleaned_abstract_pos'][i])\n",
        "  print(\"Cleaned Abstract with POS and Keywords:\\n\\t\", cleaned_data['cleaned_abstract_pos_keywords'][i])\n",
        "  print(\"Cleaned Abstract with POS and NER:\\n\\t\", cleaned_data['cleaned_abstract_pos_ner'][i])\n",
        "  print(\"Cleaned Abstract with POS and Keywords and NER:\\n\\t\", cleaned_data['cleaned_abstract_pos_keywords_ner'][i])\n",
        "  print(\"Cleaned Title:\\n\\t\", cleaned_data['cleaned_title'][i])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Insepct String Length Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "abstract_word_count = []\n",
        "title_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in cleaned_data['cleaned_abstract']:\n",
        "  abstract_word_count.append(len(i.split()))\n",
        "\n",
        "for i in cleaned_data['cleaned_title']:\n",
        "  title_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'abstract':abstract_word_count, 'title':title_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAM-o54M0IAS"
      },
      "source": [
        "### Function for Attention Mask Error Checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "gg-ohbwpgAbv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checking ner_attn_mask\n",
            "\terror: 0\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'noun_attn_mask'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/.pyenv/versions/3.9.14/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.9.14/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.9.14/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'noun_attn_mask'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[153], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[39mreturn\u001b[39;00m (failed_text_split_list, failed_text_list, failed_mask_list, failed_text_len_list, failed_mask_len_list, error_count)\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m mask \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mner_attn_mask\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnoun_attn_mask\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mverb_attn_mask\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39madj_attn_mask\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> 37\u001b[0m   tsl, tl, ml, tll, mll, error \u001b[39m=\u001b[39m attn_mask_error_checking(cleaned_data[\u001b[39m'\u001b[39m\u001b[39mcleaned_abstract\u001b[39m\u001b[39m'\u001b[39m], cleaned_data[mask])\n\u001b[1;32m     38\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mchecking \u001b[39m\u001b[39m{\u001b[39;00mmask\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39merror: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m   \u001b[39mif\u001b[39;00m error \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.9.14/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/.pyenv/versions/3.9.14/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'noun_attn_mask'"
          ]
        }
      ],
      "source": [
        "def attn_mask_error_checking(abstract_text_series, attn_mask_series):\n",
        "  text_list = []\n",
        "  text_len_list = []\n",
        "  text_split_list = []\n",
        "  mask_len_list = []\n",
        "  mask_list = []\n",
        "  # get length of string in text\n",
        "  for row in abstract_text_series:\n",
        "    text_list.append(row)\n",
        "    text_split_list.append(row.split())\n",
        "    text_len_list.append(len(row.split()))\n",
        "  # get length of attention mask\n",
        "  for row in attn_mask_series:\n",
        "    mask_list.append(row)\n",
        "    mask_len_list.append(len(row))\n",
        "    \n",
        "  failed_text_split_list = []\n",
        "  failed_text_list = []\n",
        "  failed_text_len_list = []\n",
        "  failed_mask_list = []\n",
        "  failed_mask_len_list = []\n",
        "  error_count = 0\n",
        "  # compare the length of text with the length of attention mask\n",
        "  for text_len, text_split, text, mask_len, mask in zip(text_len_list, text_split_list, text_list, mask_len_list, mask_list):\n",
        "    if text_len != mask_len:\n",
        "      # print(\"length of text is not the same as length of mask\")\n",
        "      failed_text_split_list.append(text_split)\n",
        "      failed_text_list.append(text)\n",
        "      failed_mask_list.append(mask)\n",
        "      failed_mask_len_list.append(mask_len)\n",
        "      failed_text_len_list.append(text_len)\n",
        "      error_count += 1\n",
        "        \n",
        "  return (failed_text_split_list, failed_text_list, failed_mask_list, failed_text_len_list, failed_mask_len_list, error_count)\n",
        "\n",
        "for mask in ['ner_attn_mask', 'noun_attn_mask', 'verb_attn_mask', 'adj_attn_mask']:\n",
        "  tsl, tl, ml, tll, mll, error = attn_mask_error_checking(cleaned_data['cleaned_abstract'], cleaned_data[mask])\n",
        "  print(f\"checking {mask}\\n\\terror: {error}\")\n",
        "  if error > 0:\n",
        "    print(f\"\\t{mask} text and mask lists\")\n",
        "    # print(f\"\\t{tsl}\")\n",
        "    # print(f\"\\t{tl}\")\n",
        "    # print(f\"\\t{ml}\")\n",
        "    print(f\"\\t{tll}\")\n",
        "    print(f\"\\t{mll}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc7jseOdOyA2"
      },
      "source": [
        "### Split Training and Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRIL1YDyOyA3"
      },
      "outputs": [],
      "source": [
        "abs_tr, abs_te, ttl_tr, ttl_te = train_test_split(\n",
        "  np.array(cleaned_data['cleaned_abstract']),\n",
        "  np.array(cleaned_data['cleaned_title']),\n",
        "  test_size=0.1,\n",
        "  random_state=0,\n",
        "  shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvUKlvl1OyA4"
      },
      "source": [
        "### Tokenize Title and Abstracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3dOe-5fOyA5"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(train_set, test_set, string_length, rare_word_threshold):\n",
        "  # find the number of rarewords\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(list(train_set))\n",
        "  rare_word_count = 0\n",
        "  total_word_count = 0\n",
        "  for _,freq in tokenizer.word_counts.items():\n",
        "    total_word_count = total_word_count + 1\n",
        "    if (freq < rare_word_threshold):\n",
        "      rare_word_count += 1\n",
        "    \n",
        "  # prepare a tokenizer for reviews on training data\n",
        "  tokenizer = Tokenizer(num_words=total_word_count-rare_word_count)\n",
        "  tokenizer.fit_on_texts(list(train_set))\n",
        "\n",
        "  # convert text sequences into integer sequences\n",
        "  train_set = tokenizer.texts_to_sequences(train_set) \n",
        "  test_set = tokenizer.texts_to_sequences(test_set)\n",
        "\n",
        "  # padding zero up to maximum length\n",
        "  train_set = pad_sequences(train_set, maxlen=string_length, padding='post') \n",
        "  test_set = pad_sequences(test_set, maxlen=string_length, padding='post')\n",
        "\n",
        "  # get vector size\n",
        "  vocab_size = tokenizer.num_words+1\n",
        "\n",
        "  return tokenizer, train_set, test_set, vocab_size\n",
        "\n",
        "abs_tokenizer, abs_tr, abs_te, abs_size = tokenize_text(abs_tr, abs_te, MAX_ABSTRACT_LEN, 3)\n",
        "ttl_tokenizer, ttl_tr, ttl_te, ttl_size = tokenize_text(ttl_tr, ttl_te, MAX_TITLE_LEN, 6)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Remove Empty Texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_empty_text(abstract, title):\n",
        "  indices = []\n",
        "  for i in range(len(ttl_tr)):\n",
        "      cnt = 0\n",
        "      for j in ttl_tr[i]:\n",
        "          if j!=0:\n",
        "              cnt=cnt+1\n",
        "      if (cnt == 2):\n",
        "          indices.append(i)\n",
        "\n",
        "  abstract = np.delete(abs_tr, indices, axis=0)\n",
        "  title = np.delete(ttl_tr, indices, axis=0)\n",
        "  print(f\"removed {len(indices)} empty texts.\")\n",
        "\n",
        "  return abstract, title\n",
        "\n",
        "abs_tr, ttl_tr = remove_empty_text(abs_tr, ttl_tr)\n",
        "abs_te, ttl_te = remove_empty_text(abs_te, ttl_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TaFaS9iOyA5"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session() \n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(MAX_ABSTRACT_LEN,))\n",
        "\n",
        "# embedding layer\n",
        "enc_emb =  tf.keras.layers.Embedding(abs_size, \n",
        "                                     EMBEDDING_DIMENSION, \n",
        "                                     trainable=True)(encoder_inputs)\n",
        "\n",
        "# encoder lstm 1\n",
        "encoder_lstm1 = tf.keras.layers.LSTM(LATENT_DIMENSION, \n",
        "                                     return_sequences=True, \n",
        "                                     return_state=True, \n",
        "                                     dropout=0.4, \n",
        "                                     recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# encoder lstm 2\n",
        "encoder_lstm2 = tf.keras.layers.LSTM(LATENT_DIMENSION,\n",
        "                                     return_sequences=True,\n",
        "                                     return_state=True,\n",
        "                                     dropout=0.4,\n",
        "                                     recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# encoder lstm 3\n",
        "encoder_lstm3 = tf.keras.layers.LSTM(LATENT_DIMENSION, \n",
        "                                     return_state=True, \n",
        "                                     return_sequences=True,\n",
        "                                     dropout=0.4,\n",
        "                                     recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "# embedding layer\n",
        "dec_emb_layer = tf.keras.layers.Embedding(ttl_size, \n",
        "                                          EMBEDDING_DIMENSION, \n",
        "                                          trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = tf.keras.layers.LSTM(LATENT_DIMENSION, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True,\n",
        "                                    dropout=0.4,\n",
        "                                    recurrent_dropout=0.2)\n",
        "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,\n",
        "                                                                     initial_state=[state_h, state_c])\n",
        "\n",
        "# attention layer\n",
        "attn_layer = tf.keras.layers.AdditiveAttention()\n",
        "# attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
        "attn_out = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# concat attention input and decoder LSTM output\n",
        "decoder_concat_input = tf.keras.layers.Concatenate()([decoder_outputs, attn_out])\n",
        "\n",
        "# dense layer\n",
        "decoder_dense =  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(ttl_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "# decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# define the model \n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E4k41J3OyA7"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTQyN3I7OyA8"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# train model\n",
        "history = model.fit([abs_tr, ttl_tr[:,:-1]], ttl_tr.reshape(ttl_tr.shape[0], ttl_tr.shape[1], 1)[:,1:],\n",
        "                    epochs=EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=([abs_te,ttl_te[:,:-1]], ttl_te.reshape(ttl_te.shape[0], ttl_te.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Inspect Training Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vec2Word Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reverse_target_word_index=ttl_tokenizer.index_word \n",
        "reverse_source_word_index=abs_tokenizer.index_word \n",
        "target_word_index=ttl_tokenizer.word_index"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# encode the input sequence to get the feature vector\n",
        "encoder_model = tf.keras.models.Model(inputs=encoder_inputs,\n",
        "                                      outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder setup\n",
        "# below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=(LATENT_DIMENSION,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(LATENT_DIMENSION,))\n",
        "decoder_hidden_state_input = tf.keras.layers.Input(shape=(MAX_ABSTRACT_LEN, LATENT_DIMENSION))\n",
        "\n",
        "# get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# to predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# attention inference\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = tf.keras.layers.Concatenate()([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# a dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "# decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# final decoder model\n",
        "decoder_model = tf.keras.models.Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "                                      [decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Decode Inference Output Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # encode the input as state vectors.\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq, verbose=0)\n",
        "  \n",
        "  # generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1,1))\n",
        "  \n",
        "  # populate the first word of target sequence with the start word.\n",
        "  target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "  \n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c], verbose=0)\n",
        "\n",
        "    # sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    \n",
        "    if (sampled_token != 'eostok'):\n",
        "      decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "    # exit condition: either hit max length or find stop word.\n",
        "    if (sampled_token == 'eostok' or len(decoded_sentence.split()) >= (MAX_TITLE_LEN-1)):\n",
        "      stop_condition = True\n",
        "\n",
        "    # update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seq2Abstract and Seq2Title Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seq2abstract(input_seq):\n",
        "  newString = ''\n",
        "  for i in input_seq:\n",
        "    if (i != 0):\n",
        "      newString = newString + reverse_source_word_index[i] + ' '\n",
        "  return newString\n",
        "\n",
        "def seq2title(input_seq):\n",
        "  newString = ''\n",
        "  for i in input_seq:\n",
        "    if (i != 0 and i != target_word_index['sostok']) and (i != target_word_index['eostok']):\n",
        "      newString = newString + reverse_target_word_index[i] + ' '\n",
        "  return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing Model\n",
        "### BLEU and ROUGE Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bleu_metric = BLEU()\n",
        "rouge_metric = Rouge()\n",
        "\n",
        "def evaluate_title(predicted_ttl, original_ttl):\n",
        "  # prediction and original titles both need to be string sentences\n",
        "  # get BLEU score\n",
        "  bleu_result = (bleu_metric.sentence_score(hypothesis=predicted_ttl, references=[original_ttl]))\n",
        "  bleu_score = bleu_result.score/100 # sacreBLEU gives the score in percent\n",
        "\n",
        "  # get ROUGE score\n",
        "  rouge_result = rouge_metric.get_scores(hyps=predicted_ttl, refs=original_ttl)\n",
        "  rouge_score = rouge_result[0][\"rouge-l\"][\"f\"]\n",
        "\n",
        "  # get overall F1 score\n",
        "  f1 = (2.0 * bleu_score * rouge_score) / (bleu_score + rouge_score)\n",
        "\n",
        "  return f1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Print Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(abs_te)):\n",
        "  print(\"Abstract:\", seq2abstract(abs_te[i]))\n",
        "  print(\"Original Title:\", seq2title(ttl_te[i]))\n",
        "  print(\"Predicted Title:\", decode_sequence(abs_te[i].reshape(1, MAX_ABSTRACT_LEN)))\n",
        "  print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.14 64-bit ('3.9.14')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "d50662f09ec6209d433ff0029bf9cc367be01420c8c5568a1e0b3ae42a6d5264"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
