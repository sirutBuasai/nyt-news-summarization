{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvoGHJJvOyAe"
      },
      "source": [
        "# New York Times News Summarization\n",
        "Sirut Buasai, sbausai2@wpi.edu <br>\n",
        "Jason Dykstra, jpdykstra@wpi.edu <br>\n",
        "Adam Yang ayang@wpi.edu\n",
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "emBF0izoOyAo",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4a87d7-c16a-40b0-f9a4-427ccd5e9520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 13.0 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (1.21.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (0.8.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu) (4.9.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.6.0 sacrebleu-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n",
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "# Data Processing\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Text Processing\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import pos_tag_sents\n",
        "!pip install sacrebleu\n",
        "!pip install rouge\n",
        "from sacrebleu.metrics import BLEU\n",
        "from rouge import Rouge\n",
        "\n",
        "# Model Building\n",
        "import tensorflow as tf\n",
        "from keras.utils import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Downloads\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "NER = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B73993JWevBU"
      },
      "source": [
        "## Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntkhyPUaevBU"
      },
      "outputs": [],
      "source": [
        "MAX_ABSTRACT_LEN = 30\n",
        "MAX_TITLE_LEN = 12\n",
        "LATENT_DIMENSION = 300 \n",
        "EMBEDDING_DIMENSION = 100 \n",
        "EPOCH = 10\n",
        "BATCH_SIZE = 128\n",
        "DATA_SET_RATIO = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEs_PaTROyAs"
      },
      "source": [
        "## Data Pre-processing\n",
        "### Initial Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEDTd5yNOyAu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "5f78c579-7904-4df6-8543-2af850788ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataframe shape: (53253, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                                 ID  \\\n",
              "0               0  nyt://article/178801fe-4679-5f12-985f-8344a86e...   \n",
              "1               1  nyt://article/21acedcb-a7f6-5131-99cf-d3a47e33...   \n",
              "2               2  nyt://article/357b5429-a9f8-5d33-a5eb-c013a201...   \n",
              "3               3  nyt://article/619ca4ea-50e4-59e4-97bb-f206502c...   \n",
              "4               4  nyt://article/73c49a5a-bcf1-5b8f-a15a-98d29003...   \n",
              "...           ...                                                ...   \n",
              "53248       53248  nyt://article/2f8c80d9-fa84-59ce-8393-ae0783ec...   \n",
              "53249       53249  nyt://article/a8168add-c903-52ff-abc5-4d085b33...   \n",
              "53250       53250  nyt://article/6bb0621c-387a-55eb-b172-20ec5e59...   \n",
              "53251       53251  nyt://article/8789dc1f-dd78-509a-b033-a5d8cbbf...   \n",
              "53252       53252  nyt://article/86d2300f-c8eb-5eeb-a9c2-9e8c5b2e...   \n",
              "\n",
              "                                                   title    topic  \\\n",
              "0      In Reversal, Pakistan Welcomes Outside Help Wi...  Foreign   \n",
              "1           Fighting Intensifies After Election in Kenya  Foreign   \n",
              "2                       Israel: Olmert Curbs Settlements  Foreign   \n",
              "3            Gay Muslims Pack a Dance Floor of Their Own  Foreign   \n",
              "4                    Iraqi Revelers Embrace the New Year  Foreign   \n",
              "...                                                  ...      ...   \n",
              "53248  Persian Gulf Council Retracts Statement Defend...  Foreign   \n",
              "53249  In China’s Modern Economy, a Retro Push Agains...  Foreign   \n",
              "53250     Compromise Reached on Yemen Council, U.N. Says  Foreign   \n",
              "53251  A French Education Minister Who Knows Immigran...  Foreign   \n",
              "53252  U.N. Panel Threatens to Name Those It Accuses ...  Foreign   \n",
              "\n",
              "                                                abstract  \\\n",
              "0      Pakistan’s ambassador to the U.S. said his gov...   \n",
              "1      Kenya sank deeper into trouble, with a curfew ...   \n",
              "2      Prime Minister Ehud Olmert has sent a letter t...   \n",
              "3      The monthly club night known as Gayhane is an ...   \n",
              "4      But even as partygoers embraced the New Year, ...   \n",
              "...                                                  ...   \n",
              "53248  The Gulf Cooperation Council, an organization ...   \n",
              "53249  An economic boom that has created opportunitie...   \n",
              "53250  Houthi rebels have agreed to effectively add a...   \n",
              "53251  Najat Vallaud-Belkacem, the first woman in her...   \n",
              "53252  The Independent International Commission of In...   \n",
              "\n",
              "                            Date  \\\n",
              "0      2008-01-01 05:00:00+00:00   \n",
              "1      2008-01-01 05:00:00+00:00   \n",
              "2      2008-01-01 05:00:00+00:00   \n",
              "3      2008-01-01 05:00:00+00:00   \n",
              "4      2008-01-01 05:00:00+00:00   \n",
              "...                          ...   \n",
              "53248  2015-02-20 18:03:54+00:00   \n",
              "53249  2015-02-20 18:38:24+00:00   \n",
              "53250  2015-02-20 19:14:37+00:00   \n",
              "53251  2015-02-20 19:18:47+00:00   \n",
              "53252  2015-02-20 19:58:46+00:00   \n",
              "\n",
              "                                                keywords  \n",
              "0      ['Assassinations and Attempted Assassinations'...  \n",
              "1      ['Kenya', 'Demonstrations and Riots', 'Odinga,...  \n",
              "2                                          ['West Bank']  \n",
              "3      ['Homosexuality', 'Islam', 'IMMIGRATION AND RE...  \n",
              "4      ['ARMAMENT, DEFENSE AND MILITARY FORCES', 'Iraq']  \n",
              "...                                                  ...  \n",
              "53248  ['Kirkpatrick, David D', 'Gulf Cooperation Cou...  \n",
              "53249  ['China', 'Tatlow, Didi Kirsten', \"Women's Rig...  \n",
              "53250  ['Yemen', 'Almosawa, Shuaib', 'Houthis', 'Nord...  \n",
              "53251  ['Education (K-12)', 'Alami, Aida', 'France', ...  \n",
              "53252  ['Syria', 'War Crimes, Genocide and Crimes Aga...  \n",
              "\n",
              "[53253 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-705030d3-b6e7-49d4-b5d2-cc793f7a7fee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>title</th>\n",
              "      <th>topic</th>\n",
              "      <th>abstract</th>\n",
              "      <th>Date</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>nyt://article/178801fe-4679-5f12-985f-8344a86e...</td>\n",
              "      <td>In Reversal, Pakistan Welcomes Outside Help Wi...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Pakistan’s ambassador to the U.S. said his gov...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['Assassinations and Attempted Assassinations'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>nyt://article/21acedcb-a7f6-5131-99cf-d3a47e33...</td>\n",
              "      <td>Fighting Intensifies After Election in Kenya</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Kenya sank deeper into trouble, with a curfew ...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['Kenya', 'Demonstrations and Riots', 'Odinga,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>nyt://article/357b5429-a9f8-5d33-a5eb-c013a201...</td>\n",
              "      <td>Israel: Olmert Curbs Settlements</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Prime Minister Ehud Olmert has sent a letter t...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['West Bank']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>nyt://article/619ca4ea-50e4-59e4-97bb-f206502c...</td>\n",
              "      <td>Gay Muslims Pack a Dance Floor of Their Own</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>The monthly club night known as Gayhane is an ...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['Homosexuality', 'Islam', 'IMMIGRATION AND RE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>nyt://article/73c49a5a-bcf1-5b8f-a15a-98d29003...</td>\n",
              "      <td>Iraqi Revelers Embrace the New Year</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>But even as partygoers embraced the New Year, ...</td>\n",
              "      <td>2008-01-01 05:00:00+00:00</td>\n",
              "      <td>['ARMAMENT, DEFENSE AND MILITARY FORCES', 'Iraq']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53248</th>\n",
              "      <td>53248</td>\n",
              "      <td>nyt://article/2f8c80d9-fa84-59ce-8393-ae0783ec...</td>\n",
              "      <td>Persian Gulf Council Retracts Statement Defend...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>The Gulf Cooperation Council, an organization ...</td>\n",
              "      <td>2015-02-20 18:03:54+00:00</td>\n",
              "      <td>['Kirkpatrick, David D', 'Gulf Cooperation Cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53249</th>\n",
              "      <td>53249</td>\n",
              "      <td>nyt://article/a8168add-c903-52ff-abc5-4d085b33...</td>\n",
              "      <td>In China’s Modern Economy, a Retro Push Agains...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>An economic boom that has created opportunitie...</td>\n",
              "      <td>2015-02-20 18:38:24+00:00</td>\n",
              "      <td>['China', 'Tatlow, Didi Kirsten', \"Women's Rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53250</th>\n",
              "      <td>53250</td>\n",
              "      <td>nyt://article/6bb0621c-387a-55eb-b172-20ec5e59...</td>\n",
              "      <td>Compromise Reached on Yemen Council, U.N. Says</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Houthi rebels have agreed to effectively add a...</td>\n",
              "      <td>2015-02-20 19:14:37+00:00</td>\n",
              "      <td>['Yemen', 'Almosawa, Shuaib', 'Houthis', 'Nord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53251</th>\n",
              "      <td>53251</td>\n",
              "      <td>nyt://article/8789dc1f-dd78-509a-b033-a5d8cbbf...</td>\n",
              "      <td>A French Education Minister Who Knows Immigran...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>Najat Vallaud-Belkacem, the first woman in her...</td>\n",
              "      <td>2015-02-20 19:18:47+00:00</td>\n",
              "      <td>['Education (K-12)', 'Alami, Aida', 'France', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53252</th>\n",
              "      <td>53252</td>\n",
              "      <td>nyt://article/86d2300f-c8eb-5eeb-a9c2-9e8c5b2e...</td>\n",
              "      <td>U.N. Panel Threatens to Name Those It Accuses ...</td>\n",
              "      <td>Foreign</td>\n",
              "      <td>The Independent International Commission of In...</td>\n",
              "      <td>2015-02-20 19:58:46+00:00</td>\n",
              "      <td>['Syria', 'War Crimes, Genocide and Crimes Aga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53253 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-705030d3-b6e7-49d4-b5d2-cc793f7a7fee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-705030d3-b6e7-49d4-b5d2-cc793f7a7fee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-705030d3-b6e7-49d4-b5d2-cc793f7a7fee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "raw_data_path = '/content/gdrive/My Drive/Fourth Year/Natural Language Processing/Final Project/NYT_Dataset.csv'\n",
        "raw_data = pd.read_csv(raw_data_path)\n",
        "raw_data = raw_data[:int(DATA_SET_RATIO*len(raw_data))]\n",
        "print(f'dataframe shape: {raw_data.shape}')\n",
        "raw_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP0xgBIqOyAv"
      },
      "source": [
        "### Clean Data\n",
        "#### Part of Speech Processing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt2rCg-K7bn-"
      },
      "outputs": [],
      "source": [
        "def pos_processing(abstract_sentences):\n",
        "  abstract_tokens = pd.Series(abstract_sentences.apply(lambda sentence: sentence.split()))\n",
        "\n",
        "  # identify parts-of-speech; pos_tag requires list of tokens\n",
        "  abstract_pos = pd.Series(pos_tag_sents(abstract_tokens))\n",
        "\n",
        "  # filter non-desirable parts-of-speech\n",
        "  nounsList = ['NN', 'NNS', 'NNP', 'NNPS'] # Nouns\n",
        "  verbsList = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VPZ'] # Verbs\n",
        "  adjList = ['JJ', 'JJR', 'JJS'] # Adjectives\n",
        "  pos_list = nounsList + verbsList + adjList\n",
        "  abstract_pos_filtered = abstract_pos.apply(lambda words: ' '.join([1 if pair[1] in pos_list else 0 for pair in words]))\n",
        "\n",
        "  return abstract_pos_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRRQSO8eevBY"
      },
      "source": [
        "#### NER Processing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eN1mcbw8rbj"
      },
      "outputs": [],
      "source": [
        "def create_ne_attn_mask(entities):\n",
        "  # extract named entities\n",
        "  named_entities = entities.ents\n",
        "  # initialize attention mask\n",
        "  attn_mask = [0 for i in range(len(entities))]\n",
        "\n",
        "  # assign 1's to positions in attn mask corresponding to named-entity positions\n",
        "  for entity in named_entities:\n",
        "      attn_mask[entity.start: entity.end] = [1 for i in range(entity.start,entity.end)]\n",
        "\n",
        "  return attn_mask\n",
        "\n",
        "def ner_processing(abstract_sentences):\n",
        "  # identify entities for each abstract\n",
        "  # NOTE: this is supposedly faster if we use nlp.pipe, but we can look into that tomorrow ...\n",
        "  abs_entities = pd.Series(abstract_sentences.apply(lambda sentence: NER(sentence)))\n",
        "\n",
        "  # extract the original sentences, but now with split contractions\n",
        "  original_sentence = pd.Series(abs_entities.apply(lambda entities: ' '.join([token.orth_ for token in entities])))\n",
        "\n",
        "  # create attention mask(s) using the NE's\n",
        "  ne_attention_mask = abs_entities.apply(lambda entities: create_ne_attn_mask(entities))\n",
        "\n",
        "\n",
        "  return original_sentence, ne_attention_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPpI_mowevBZ"
      },
      "source": [
        "#### Clean Text Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "dvJXzEeFOyAw",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "6fdd2288-e972-4a4e-b7ef-6cc9566caf7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataframe shape: (52908, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   title  \\\n",
              "0      in reversal, pakistan welcomes outside help wi...   \n",
              "1           fighting intensifies after election in kenya   \n",
              "2                       israel: olmert curbs settlements   \n",
              "3            gay muslims pack a dance floor of their own   \n",
              "4                    iraqi revelers embrace the new year   \n",
              "...                                                  ...   \n",
              "52903  persian gulf council retracts statement defend...   \n",
              "52904  in china’s modern economy, a retro push agains...   \n",
              "52905     compromise reached on yemen council, u.n. says   \n",
              "52906  a french education minister who knows immigran...   \n",
              "52907  u.n. panel threatens to name those it accuses ...   \n",
              "\n",
              "                                                abstract  \\\n",
              "0      pakistan’s ambassador to the u.s. said his gov...   \n",
              "1      kenya sank deeper into trouble, with a curfew ...   \n",
              "2      prime minister ehud olmert has sent a letter t...   \n",
              "3      the monthly club night known as gayhane is an ...   \n",
              "4      but even as partygoers embraced the new year, ...   \n",
              "...                                                  ...   \n",
              "52903  the gulf cooperation council, an organization ...   \n",
              "52904  an economic boom that has created opportunitie...   \n",
              "52905  houthi rebels have agreed to effectively add a...   \n",
              "52906  najat vallaud-belkacem, the first woman in her...   \n",
              "52907  the independent international commission of in...   \n",
              "\n",
              "                                           cleaned_title  \\\n",
              "0      sostok reversal pakistan welcomes outside help...   \n",
              "1      sostok fighting intensifies election kenya eostok   \n",
              "2          sostok israel olmert curbs settlements eostok   \n",
              "3             sostok gay muslims pack dance floor eostok   \n",
              "4          sostok iraqi revelers embrace new year eostok   \n",
              "...                                                  ...   \n",
              "52903  sostok persian gulf council retracts statement...   \n",
              "52904  sostok chinas modern economy retro push women ...   \n",
              "52905  sostok compromise reached yemen council un say...   \n",
              "52906  sostok french education minister knows immigra...   \n",
              "52907  sostok un panel threatens name accuses war cri...   \n",
              "\n",
              "                                        cleaned_abstract  \n",
              "0      pakistans ambassador us said government would ...  \n",
              "1      kenya sank deeper trouble curfew imposed kisum...  \n",
              "2      prime minister ehud olmert sent letter defense...  \n",
              "3      monthly club night known gayhane alltoorare op...  \n",
              "4      even partygoers embraced new year surge attack...  \n",
              "...                                                  ...  \n",
              "52903  gulf cooperation council organization persian ...  \n",
              "52904  economic boom created opportunities women also...  \n",
              "52905  houthi rebels agreed effectively add upper cha...  \n",
              "52906  najat vallaudbelkacem first woman post product...  \n",
              "52907  independent international commission inquiry s...  \n",
              "\n",
              "[52908 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25573200-c0e2-4808-9c74-76f7d208fbcd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>cleaned_title</th>\n",
              "      <th>cleaned_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in reversal, pakistan welcomes outside help wi...</td>\n",
              "      <td>pakistan’s ambassador to the u.s. said his gov...</td>\n",
              "      <td>sostok reversal pakistan welcomes outside help...</td>\n",
              "      <td>pakistans ambassador us said government would ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fighting intensifies after election in kenya</td>\n",
              "      <td>kenya sank deeper into trouble, with a curfew ...</td>\n",
              "      <td>sostok fighting intensifies election kenya eostok</td>\n",
              "      <td>kenya sank deeper trouble curfew imposed kisum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>israel: olmert curbs settlements</td>\n",
              "      <td>prime minister ehud olmert has sent a letter t...</td>\n",
              "      <td>sostok israel olmert curbs settlements eostok</td>\n",
              "      <td>prime minister ehud olmert sent letter defense...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gay muslims pack a dance floor of their own</td>\n",
              "      <td>the monthly club night known as gayhane is an ...</td>\n",
              "      <td>sostok gay muslims pack dance floor eostok</td>\n",
              "      <td>monthly club night known gayhane alltoorare op...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>iraqi revelers embrace the new year</td>\n",
              "      <td>but even as partygoers embraced the new year, ...</td>\n",
              "      <td>sostok iraqi revelers embrace new year eostok</td>\n",
              "      <td>even partygoers embraced new year surge attack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52903</th>\n",
              "      <td>persian gulf council retracts statement defend...</td>\n",
              "      <td>the gulf cooperation council, an organization ...</td>\n",
              "      <td>sostok persian gulf council retracts statement...</td>\n",
              "      <td>gulf cooperation council organization persian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52904</th>\n",
              "      <td>in china’s modern economy, a retro push agains...</td>\n",
              "      <td>an economic boom that has created opportunitie...</td>\n",
              "      <td>sostok chinas modern economy retro push women ...</td>\n",
              "      <td>economic boom created opportunities women also...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52905</th>\n",
              "      <td>compromise reached on yemen council, u.n. says</td>\n",
              "      <td>houthi rebels have agreed to effectively add a...</td>\n",
              "      <td>sostok compromise reached yemen council un say...</td>\n",
              "      <td>houthi rebels agreed effectively add upper cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52906</th>\n",
              "      <td>a french education minister who knows immigran...</td>\n",
              "      <td>najat vallaud-belkacem, the first woman in her...</td>\n",
              "      <td>sostok french education minister knows immigra...</td>\n",
              "      <td>najat vallaudbelkacem first woman post product...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52907</th>\n",
              "      <td>u.n. panel threatens to name those it accuses ...</td>\n",
              "      <td>the independent international commission of in...</td>\n",
              "      <td>sostok un panel threatens name accuses war cri...</td>\n",
              "      <td>independent international commission inquiry s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52908 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25573200-c0e2-4808-9c74-76f7d208fbcd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25573200-c0e2-4808-9c74-76f7d208fbcd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25573200-c0e2-4808-9c74-76f7d208fbcd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def preprocess_data(df):\n",
        "  # drop unnecessary columns\n",
        "  unused_columns = ['Unnamed: 0', 'Date', 'ID', 'topic', 'keywords']\n",
        "  df.drop(unused_columns, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "  # drop dupliates and nan rows\n",
        "  df.drop_duplicates(subset=['abstract'], inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "  df.dropna(axis=0, inplace=True)\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  # convert texts to lowercase\n",
        "  df['abstract'] = df['abstract'].str.lower()\n",
        "  df['title'] = df['title'].str.lower()\n",
        "\n",
        "  # strip special characters\n",
        "  df['cleaned_title'] = df['title'].apply(lambda string: re.sub(\"[^a-zA-Z0-9 ]+\", '', string))\n",
        "  df['cleaned_abstract'] = df['abstract'].apply(lambda string: re.sub(\"[^a-zA-Z0-9 ]+\", '', string))\n",
        "\n",
        "  # convert string to list\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda string: string.split())\n",
        "  df['cleaned_abstract'] = df['cleaned_abstract'].apply(lambda string: string.split())\n",
        "\n",
        "  # remove stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda sentence: [word for word in sentence if word not in (stop_words)])\n",
        "  df['cleaned_abstract'] = df['cleaned_abstract'].apply(lambda sentence: [word for word in sentence if word not in (stop_words)])\n",
        "\n",
        "  # convert list back to string\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda sentence: \" \".join(word for word in sentence))\n",
        "  df['cleaned_abstract'] = df['cleaned_abstract'].apply(lambda sentence: \" \".join(word for word in sentence))\n",
        "\n",
        "    # generate noun, verb, adj attention mask from parts-of-speech; requires string sentences\n",
        "  df['cleaned_abstract'] = pos_processing(df['cleaned_abstract'])\n",
        "\n",
        "#   # ATTENTION MASK GENERATION NEEDS TO BE LAST PART OF PROCESSING FUNCTION\n",
        "#   # identify named-entities; NER requires string sentences\n",
        "#   df['cleaned_abstract'], df['ner_attn_mask'] = ner_processing(df['cleaned_abstract'])\n",
        "    \n",
        "  # add start and end tokens for title\n",
        "  df['cleaned_title'] = df['cleaned_title'].apply(lambda text: 'sostok ' + text + ' eostok')\n",
        "\n",
        "  return df\n",
        "\n",
        "cleaned_data = preprocess_data(raw_data)\n",
        "print(f'dataframe shape: {cleaned_data.shape}')\n",
        "cleaned_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6C07JfjSIPkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf8e894-68ce-4446-a36e-58c764c97b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abstract: pakistans ambassador us said government would endorse separate inquiry modeled one carried un assassination rafik hariri lebanon 2005\n",
            "Title: sostok reversal pakistan welcomes outside help inquiry bhutto eostok\n",
            "\n",
            "\n",
            "Abstract: kenya sank deeper trouble curfew imposed kisumu countrys thirdlargest city ethnic fighting intensifying 100 people killed electionrelated violence\n",
            "Title: sostok fighting intensifies election kenya eostok\n",
            "\n",
            "\n",
            "Abstract: prime minister ehud olmert sent letter defense housing agriculture ministers saying defense ministers authorization would required new building planning land expropriation jewish settlements west bank\n",
            "Title: sostok israel olmert curbs settlements eostok\n",
            "\n",
            "\n",
            "Abstract: monthly club night known gayhane alltoorare opportunity gay muslims merge immigrant cultures sexual identities\n",
            "Title: sostok gay muslims pack dance floor eostok\n",
            "\n",
            "\n",
            "Abstract: even partygoers embraced new year surge attacks monday served potent reminder 2007 bloodiest record\n",
            "Title: sostok iraqi revelers embrace new year eostok\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "  print(\"Abstract:\", cleaned_data['cleaned_abstract'][i])\n",
        "  print(\"Title:\", cleaned_data['cleaned_title'][i])\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhjEUjR0IPkJ"
      },
      "source": [
        "### Insepct String Length Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwiQEDcFIPkK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "f4fc426e-7603-40d3-ad44-66f7013e5cce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "abstract_word_count = []\n",
        "title_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in cleaned_data['cleaned_abstract']:\n",
        "  abstract_word_count.append(len(i.split()))\n",
        "\n",
        "for i in cleaned_data['cleaned_title']:\n",
        "  title_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'abstract':abstract_word_count, 'title':title_word_count})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAM-o54M0IAS"
      },
      "source": [
        "### Function for Attention Mask Error Checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg-ohbwpgAbv"
      },
      "outputs": [],
      "source": [
        "def attn_mask_error_checking(abstract_text_series, attn_mask_series):\n",
        "  text_list = []\n",
        "  text_len_list = []\n",
        "  text_split_list = []\n",
        "  mask_len_list = []\n",
        "  mask_list = []\n",
        "  # get length of string in text\n",
        "  for row in abstract_text_series:\n",
        "    text_list.append(row)\n",
        "    text_split_list.append(row.split())\n",
        "    text_len_list.append(len(row.split()))\n",
        "  # get length of attention mask\n",
        "  for row in attn_mask_series:\n",
        "    mask_list.append(row)\n",
        "    mask_len_list.append(len(row))\n",
        "    \n",
        "  failed_text_split_list = []\n",
        "  failed_text_list = []\n",
        "  failed_text_len_list = []\n",
        "  failed_mask_list = []\n",
        "  failed_mask_len_list = []\n",
        "  error_count = 0\n",
        "  # compare the length of text with the length of attention mask\n",
        "  for text_len, text_split, text, mask_len, mask in zip(text_len_list, text_split_list, text_list, mask_len_list, mask_list):\n",
        "    if text_len != mask_len:\n",
        "      print(\"length of text is not the same as length of mask\")\n",
        "      failed_text_split_list.append(text_split)\n",
        "      failed_text_list.append(text)\n",
        "      failed_mask_list.append(mask)\n",
        "      failed_mask_len_list.append(mask_len)\n",
        "      failed_text_len_list.append(text_len)\n",
        "      error_count += 1\n",
        "        \n",
        "  return (failed_text_split_list, failed_text_list, failed_mask_list, failed_text_len_list, failed_mask_len_list, error_count)\n",
        "\n",
        "for mask in ['ner_attn_mask', 'noun_attn_mask', 'verb_attn_mask', 'adj_attn_mask']:\n",
        "  tsl, tl, ml, tll, mll, error = attn_mask_error_checking(cleaned_data['cleaned_abstract'], cleaned_data[mask])\n",
        "  print(f\"checking {mask}\\n\\terror: {error}\")\n",
        "  if error > 0:\n",
        "    print(f\"\\t{mask} text and mask lists\")\n",
        "    # print(f\"\\t{tsl})\n",
        "    # print(f\"\\t{tl})\n",
        "    # print(f\"\\t{ml})\n",
        "    # print(f\"\\t{tll})\n",
        "    # print(f\"\\t{mll})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc7jseOdOyA2"
      },
      "source": [
        "### Split Training and Testing Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRIL1YDyOyA3"
      },
      "outputs": [],
      "source": [
        "abs_tr, abs_te, ttl_tr, ttl_te = train_test_split(\n",
        "  np.array(cleaned_data['cleaned_abstract']),\n",
        "  np.array(cleaned_data['cleaned_title']),\n",
        "  test_size=0.1,\n",
        "  random_state=0,\n",
        "  shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvUKlvl1OyA4"
      },
      "source": [
        "### Tokenize Title and Abstracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3dOe-5fOyA5"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(train_set, test_set, string_length, rare_word_threshold):\n",
        "  # find the number of rarewords\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(list(train_set))\n",
        "  rare_word_count = 0\n",
        "  total_word_count = 0\n",
        "  for _,freq in tokenizer.word_counts.items():\n",
        "    total_word_count = total_word_count + 1\n",
        "    if (freq < rare_word_threshold):\n",
        "      rare_word_count += 1\n",
        "    \n",
        "  # prepare a tokenizer for reviews on training data\n",
        "  tokenizer = Tokenizer(num_words=total_word_count-rare_word_count)\n",
        "  tokenizer.fit_on_texts(list(train_set))\n",
        "\n",
        "  # convert text sequences into integer sequences\n",
        "  train_set = tokenizer.texts_to_sequences(train_set) \n",
        "  test_set = tokenizer.texts_to_sequences(test_set)\n",
        "\n",
        "  # padding zero up to maximum length\n",
        "  train_set = pad_sequences(train_set, maxlen=string_length, padding='post') \n",
        "  test_set = pad_sequences(test_set, maxlen=string_length, padding='post')\n",
        "\n",
        "  # get vector size\n",
        "  vocab_size = tokenizer.num_words+1\n",
        "\n",
        "  return tokenizer, train_set, test_set, vocab_size\n",
        "\n",
        "abs_tokenizer, abs_tr, abs_te, abs_size = tokenize_text(abs_tr, abs_te, MAX_ABSTRACT_LEN, 3)\n",
        "ttl_tokenizer, ttl_tr, ttl_te, ttl_size = tokenize_text(ttl_tr, ttl_te, MAX_TITLE_LEN, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iDFNFfCIPkO"
      },
      "source": [
        "### Remove Empty Texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfcHV84WIPkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df1b1ada-fca6-4eb2-ceef-e8bdbc096b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "removed 148 empty texts.\n",
            "removed 0 empty texts.\n"
          ]
        }
      ],
      "source": [
        "def remove_empty_text(abstract, title):\n",
        "  indices = []\n",
        "  for i in range(len(ttl_tr)):\n",
        "      cnt = 0\n",
        "      for j in ttl_tr[i]:\n",
        "          if j!=0:\n",
        "              cnt=cnt+1\n",
        "      if (cnt == 2):\n",
        "          indices.append(i)\n",
        "\n",
        "  abstract = np.delete(abs_tr, indices, axis=0)\n",
        "  title = np.delete(ttl_tr, indices, axis=0)\n",
        "  print(f\"removed {len(indices)} empty texts.\")\n",
        "\n",
        "  return abstract, title\n",
        "\n",
        "abs_tr, ttl_tr = remove_empty_text(abs_tr, ttl_tr)\n",
        "abs_te, ttl_te = remove_empty_text(abs_te, ttl_te)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TaFaS9iOyA5"
      },
      "source": [
        "## Build LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T4JdesXIPkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b587af-047b-4753-ee18-94462abc4251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 30, 100)      1754800     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 30, 300),    481200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 30, 300),    721200      ['lstm[0][0]']                   \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    598500      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 30, 300),    721200      ['lstm_1[0][0]']                 \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 300),  481200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 300)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention_layer (Attention)    (None, 30, 300)      0           ['lstm_2[0][0]',                 \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 30, 600)      0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention_layer[0][0]']        \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 30, 5985)    3596985     ['concatenate[0][0]']            \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,355,085\n",
            "Trainable params: 8,355,085\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session() \n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = tf.keras.layers.Input(shape=(MAX_ABSTRACT_LEN,))\n",
        "\n",
        "# embedding layer\n",
        "enc_emb =  tf.keras.layers.Embedding(abs_size, \n",
        "                                     EMBEDDING_DIMENSION, \n",
        "                                     trainable=True)(encoder_inputs)\n",
        "\n",
        "# encoder lstm 1\n",
        "encoder_lstm1 = tf.keras.layers.LSTM(LATENT_DIMENSION, \n",
        "                                     return_sequences=True, \n",
        "                                     return_state=True, \n",
        "                                     dropout=0.4, \n",
        "                                     recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "# encoder lstm 2\n",
        "encoder_lstm2 = tf.keras.layers.LSTM(LATENT_DIMENSION,\n",
        "                                     return_sequences=True,\n",
        "                                     return_state=True,\n",
        "                                     dropout=0.4,\n",
        "                                     recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "# encoder lstm 3\n",
        "encoder_lstm3 = tf.keras.layers.LSTM(LATENT_DIMENSION, \n",
        "                                     return_state=True, \n",
        "                                     return_sequences=True,\n",
        "                                     dropout=0.4,\n",
        "                                     recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
        "\n",
        "# embedding layer\n",
        "dec_emb_layer = tf.keras.layers.Embedding(ttl_size, \n",
        "                                          EMBEDDING_DIMENSION, \n",
        "                                          trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = tf.keras.layers.LSTM(LATENT_DIMENSION, \n",
        "                                    return_sequences=True, \n",
        "                                    return_state=True,\n",
        "                                    dropout=0.4,\n",
        "                                    recurrent_dropout=0.2)\n",
        "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,\n",
        "                                                                     initial_state=[state_h, state_c])\n",
        "\n",
        "# NOTE: taking attention layer out for now since tutorial uses custom attention layer\n",
        "# attention layer\n",
        "attn_layer = tf.keras.layers.AdditiveAttention(name='attention_layer')\n",
        "attn_out = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# concat attention input and decoder LSTM output\n",
        "decoder_concat_input = tf.keras.layers.Concatenate()([decoder_outputs, attn_out])\n",
        "\n",
        "# dense layer\n",
        "decoder_dense =  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(ttl_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "# decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# define the model \n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E4k41J3OyA7"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTQyN3I7OyA8"
      },
      "outputs": [],
      "source": [
        "# initialize model\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# train model\n",
        "history = model.fit([abs_tr, ttl_tr[:,:-1]], ttl_tr.reshape(ttl_tr.shape[0], ttl_tr.shape[1], 1)[:,1:],\n",
        "                    epochs=EPOCH,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    validation_data=([abs_te,ttl_te[:,:-1]], ttl_te.reshape(ttl_te.shape[0], ttl_te.shape[1], 1)[:,1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vML_PeR6IPkS"
      },
      "source": [
        "### Inspect Training Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-icMlXh7IPkS"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P_gfbSyIPkS"
      },
      "source": [
        "### Vec2Word Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ9G1-NkIPkT"
      },
      "outputs": [],
      "source": [
        "reverse_target_word_index=ttl_tokenizer.index_word \n",
        "reverse_source_word_index=abs_tokenizer.index_word \n",
        "target_word_index=ttl_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zMEZYdRIPkT"
      },
      "source": [
        "## Build Inference Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzB-UmgFIPkT"
      },
      "outputs": [],
      "source": [
        "# encode the input sequence to get the feature vector\n",
        "encoder_model = tf.keras.models.Model(inputs=encoder_inputs,\n",
        "                                      outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder setup\n",
        "# below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=(LATENT_DIMENSION,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(LATENT_DIMENSION,))\n",
        "decoder_hidden_state_input = tf.keras.layers.Input(shape=(MAX_ABSTRACT_LEN, LATENT_DIMENSION))\n",
        "\n",
        "# get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \n",
        "# to predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# NOTE: taking attention layer out for now since tutorial uses custom attention layer\n",
        "# attention inference\n",
        "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
        "decoder_inf_concat = tf.keras.layers.Concatenate()([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# a dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
        "# decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# final decoder model\n",
        "decoder_model = tf.keras.models.Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "                                      [decoder_outputs2] + [state_h2, state_c2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTK_4ZytIPkT"
      },
      "source": [
        "### Decode Inference Output Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_Um9ftfIPkU"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # encode the input as state vectors.\n",
        "  e_out, e_h, e_c = encoder_model.predict(input_seq, verbose=0)\n",
        "  \n",
        "  # generate empty target sequence of length 1.\n",
        "  target_seq = np.zeros((1,1))\n",
        "  \n",
        "  # populate the first word of target sequence with the start word.\n",
        "  target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  while not stop_condition:\n",
        "  \n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c], verbose=0)\n",
        "\n",
        "    # sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "    \n",
        "    if (sampled_token != 'eostok'):\n",
        "      decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "    # exit condition: either hit max length or find stop word.\n",
        "    if (sampled_token == 'eostok' or len(decoded_sentence.split()) >= (MAX_TITLE_LEN-1)):\n",
        "      stop_condition = True\n",
        "\n",
        "    # update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "    # update internal states\n",
        "    e_h, e_c = h, c\n",
        "\n",
        "  return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq9CRYNgIPkU"
      },
      "source": [
        "### Seq2Abstract and Seq2Title Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn9iTyheIPkU"
      },
      "outputs": [],
      "source": [
        "def seq2abstract(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "      if (i != 0):\n",
        "        newString = newString + reverse_source_word_index[i] + ' '\n",
        "    return newString\n",
        "\n",
        "def seq2title(input_seq):\n",
        "    newString = ''\n",
        "    for i in input_seq:\n",
        "      if (i != 0 and i != target_word_index['sostok']) and (i != target_word_index['eostok']):\n",
        "        newString = newString + reverse_target_word_index[i] + ' '\n",
        "    return newString"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ9_BWAUIPkV"
      },
      "source": [
        "## Testing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I7uGihvIPkV"
      },
      "outputs": [],
      "source": [
        "for i in range(len(abs_te)):\n",
        "  print(\"Abstract:\", seq2abstract(abs_te[i]))\n",
        "  print(\"Original Title:\", seq2title(ttl_te[i]))\n",
        "  print(\"Predicted Title:\", decode_sequence(abs_te[i].reshape(1, MAX_ABSTRACT_LEN)))\n",
        "  print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.14 64-bit ('3.9.14')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.14"
    },
    "vscode": {
      "interpreter": {
        "hash": "d50662f09ec6209d433ff0029bf9cc367be01420c8c5568a1e0b3ae42a6d5264"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}